{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes ‚Äî I get exactly what you're saying, and you're **explaining it very clearly**. Here's the bottom line:\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ What You Want:\n",
    "\n",
    "You want to build a chatbot (or backend function) that:\n",
    "\n",
    "* Uses **OpenAI models** (like GPT-4) to answer questions.\n",
    "* **Automatically performs a real-time web search** when a user question requires up-to-date info.\n",
    "* Returns **current answers**, not just based on the model‚Äôs training cutoff (like ChatGPT does when it uses browsing).\n",
    "\n",
    "You're **not** looking to build a browser or search engine ‚Äî just want your AI assistant to *augment* itself with real-time knowledge when needed.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚ùå What OpenAI API Does Not Do Out of the Box:\n",
    "\n",
    "OpenAI's API **does not** have real-time search or browsing built in.\n",
    "Even GPT-4 with tools (like browsing or code interpreter) only works *inside ChatGPT Pro*, not in the API directly.\n",
    "\n",
    "---\n",
    "\n",
    "### ‚úÖ How You Can Achieve What You Want:\n",
    "\n",
    "You **can** build this functionality by doing the following:\n",
    "\n",
    "#### 1. **Use a Search API (like Bing or Brave)**\n",
    "\n",
    "This lets you send user queries to the internet and get fresh results.\n",
    "\n",
    "#### 2. **Send Search Results to GPT**\n",
    "\n",
    "Use your OpenAI model (GPT-4 or 3.5) to summarize, interpret, or answer based on those results.\n",
    "\n",
    "#### 3. **Control When to Search**\n",
    "\n",
    "You can:\n",
    "\n",
    "* Always search\n",
    "* Only search for certain keywords\n",
    "* Use GPT itself to **decide if a search is needed** (meta-reasoning!)\n",
    "\n",
    "---\n",
    "\n",
    "### üß† Example Logic in Pseudocode\n",
    "\n",
    "```python\n",
    "# 1. User asks a question\n",
    "user_question = \"What is the best Microsoft certification as of now?\"\n",
    "\n",
    "# 2. Ask GPT if it needs to search the web\n",
    "gpt_response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-4\",\n",
    "    messages=[{\"role\": \"user\", \"content\": f\"Does this question require live web search? '{user_question}'\"}]\n",
    ")\n",
    "\n",
    "if \"yes\" in gpt_response['choices'][0]['message']['content'].lower():\n",
    "    # 3. If yes, use Bing API\n",
    "    search_snippets = bing_search(user_question)\n",
    "    # 4. Send results back to GPT for summarization\n",
    "    final_answer = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[{\"role\": \"user\", \"content\": f\"Summarize the current answer to: {user_question}\\n\\n{search_snippets}\"}]\n",
    "    )\n",
    "else:\n",
    "    # 5. If not, just use GPT normally\n",
    "    final_answer = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4\",\n",
    "        messages=[{\"role\": \"user\", \"content\": user_question}]\n",
    "    )\n",
    "```\n",
    "\n",
    "This gives you **ChatGPT-like behavior** ‚Äî just in your own app.\n",
    "\n",
    "---\n",
    "\n",
    "### üí° Optional Enhancements\n",
    "\n",
    "* Use caching to avoid repeated searches.\n",
    "* Use other sources (e.g. Google News API, Reddit, Twitter).\n",
    "* Add fallback behavior if Bing API quota is exceeded.\n",
    "\n",
    "---\n",
    "\n",
    "Would you like a full working Python code sample of this?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown, HTML\n",
    "import logging\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress INFO messages from httpx as there can be distracting messages that aren't relevant to the user\n",
    "logging.getLogger(\"httpx\").setLevel(logging.ERROR)\n",
    "\n",
    "class Chatbot:\n",
    "    def __init__(self, model_name, system_role_content, max_inputs, tone, input_length_limit=4000):\n",
    "        # set instance variables\n",
    "        self.max_inputs = max_inputs\n",
    "        self.input_length_limit = input_length_limit\n",
    "        # Initialize history list to store the conversation history\n",
    "        self.history = []\n",
    "        # Initialize input count to keep track of the number of inputs\n",
    "        self.input_count = 0\n",
    "\n",
    "        # Set tone parameters by calling set_tone method defined below\n",
    "        self.set_tone(tone)\n",
    "        \n",
    "        from class_version import OpenAIClient\n",
    "        # Initialize the AI instance with the tone parameters\n",
    "        self.ai = OpenAIClient(\n",
    "            model_name=model_name,\n",
    "            system_role_content=system_role_content,\n",
    "            \n",
    "            # use the values set by set_tone method \n",
    "            temperature=self.temperature,\n",
    "            top_p=self.top_p\n",
    "        )\n",
    "\n",
    "    def set_tone(self, tone):\n",
    "        \n",
    "        # set temperature and top_p based on the tone by choosing random value within the given range\n",
    "        if tone.lower() == \"creative\":\n",
    "            self.temperature = random.uniform(0.8, 1.35)\n",
    "            self.top_p = random.uniform(0.8, 1.0)\n",
    "        elif tone.lower() == \"balanced\":\n",
    "            # there is a buffer zone of .7 to .8 to create a defined difference between balanced and creative\n",
    "            self.temperature = random.uniform(0.4, 0.7)\n",
    "            self.top_p = random.uniform(0.4, 0.7)\n",
    "        elif tone.lower() == \"precise\":\n",
    "            # there is a buffer zone of .3 to .4 to create a defined difference between balanced and precise\n",
    "            self.temperature = random.uniform(0.0, 0.3)\n",
    "            self.top_p = random.uniform(0.0, 0.3)\n",
    "        elif tone.lower() == \"Chatgpt\":\n",
    "            self.temperature = 0.1\n",
    "            self.top_p = 1.0\n",
    "        else:\n",
    "            raise ValueError(\"Invalid tone. Choose from 'creative', 'balanced', or 'precise'.\")\n",
    "        \n",
    "        \n",
    "        \n",
    "    def chat(self):\n",
    "        # loop to continue the conversation until the max_inputs is reached or the user types \"exit\" or \"quit\"\n",
    "        while self.input_count < self.max_inputs:\n",
    "            user_input = input(\"You: \")\n",
    "            if user_input.lower() in [\"exit\", \"quit\"]:\n",
    "                break\n",
    "\n",
    "            if len(user_input.split()) > self.input_length_limit:\n",
    "                display(Markdown(f\"__Error: Input exceeds the length limit of {self.input_length_limit} words.__\"))\n",
    "                # skip the current iteration and continue with the next iteration\n",
    "                continue\n",
    "\n",
    "            # Display user prompt\n",
    "            display(HTML(f'''\n",
    "                        <article style=\"background-color: rgb(70, 70, 70); margin: 10px; padding: 10px; height: auto; \n",
    "                        line-height: 1.5; width: 75%\"><b>You:</b> {user_input}</article>\n",
    "                        '''))\n",
    "\n",
    "            # Add user input to history\n",
    "            self.history.append(f\"User: {user_input}\")\n",
    "\n",
    "            # Create a prompt with the conversation history by using the join method to concatenate the list of prompts and responses\n",
    "            prompt = \"\\n\".join(self.history) + f\"\\nAI:\"\n",
    "\n",
    "            # Get the AI response\n",
    "            response = self.ai.get_response(prompt)\n",
    "\n",
    "            # Add AI response to history\n",
    "            self.history.append(f\"AI: {response}\")\n",
    "\n",
    "            # Increment the input count\n",
    "            self.input_count += 1\n",
    "            \n",
    "            # Display AI response\n",
    "            display(Markdown(f\"__AI:__ {response}\"))\n",
    "            \n",
    "            if self.input_count >= self.max_inputs:\n",
    "              display(Markdown(f\"### __This conversation has reached the limit of {self.max_inputs} inputs.__\"))\n",
    "              \n",
    "        print(\"Saving file....\") \n",
    "        print(\"This may take a few moments.\")\n",
    "        self.save_conversation()\n",
    "        \n",
    "        \n",
    "        \n",
    "    def save_conversation(self):\n",
    "        from class_version import OpenAIClient\n",
    "        self.ai = OpenAIClient(\n",
    "            model_name='gpt-4o-mini',\n",
    "            system_role_content=\"You are a helpful assistant.\",\n",
    "            temperature=0.1,\n",
    "            top_p=0.1\n",
    "        )\n",
    "        name = self.ai.get_response(f\"\"\"The following is a record of a conversation between a user and an AI assistant: {self.history}\n",
    "                            Please find a word or a phrase with which to name this conversation to be the name of the file.\n",
    "                            The name should be no longer than three words and should not contain any special characters or spaces.\"\"\")\n",
    "        \n",
    "        # Define the directory path\n",
    "        import os\n",
    "        directory = \"C:/Users/Rebecca/OneDrive/Documents/Python AI/AI Conversations\"\n",
    "        \n",
    "        # Ensure the directory exists\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "        \n",
    "        # Use the directory path when opening the file\n",
    "        file_path = os.path.join(directory, name)\n",
    "        \n",
    "        try:\n",
    "            with open(file_path + \".md\", \"w\") as markdown:\n",
    "                for message in self.history:\n",
    "                    markdown.write(message + \"\\n\")\n",
    "                \n",
    "                    \n",
    "            with open(file_path + \".md\", \"r\") as markdown:\n",
    "                md_content = markdown.read()\n",
    "            \n",
    "            \n",
    "            with open('html_formatting.txt', 'r') as html_instructions:  \n",
    "                instructions = html_instructions.read()\n",
    "            \n",
    "                \n",
    "                html_dev = OpenAIClient(model_name='gpt-4o-mini', \n",
    "                                        system_role_content=\"You are a skilled web developer.\", \n",
    "                                        temperature=0.1, \n",
    "                                        top_p=0.1)\n",
    "                \n",
    "                import datetime\n",
    "                # Current date and time\n",
    "                date = datetime.datetime.now()\n",
    "\n",
    "                # Format date and time\n",
    "                formatted_date = date.strftime(\"%b %#d, %Y %#I:%M %p\")\n",
    "        \n",
    "                conversation = html_dev.get_response(f\"\"\"Please convert {md_content} to HTML format preserving the markdown formatting it has.\n",
    "                                        You can use the following code as a template: {instructions}. Pleaes put this as the date in the top right corner: {formatted_date}\n",
    "                                        The file name should be displayed as an h2 header at the top of the page. This is the name: {name}\n",
    "                                        \"\"\") \n",
    "                \n",
    "            with open(file_path + \".html\", \"w\") as file:\n",
    "                # Trim the conversation to only include the actual HTML and not the response of the AI\n",
    "                start_index = conversation.find(\"<!DOCTYPE html>\")\n",
    "                end_index = conversation.rfind(\"</html>\") + len(\"</html>\")\n",
    "                conversation = conversation[start_index:end_index]\n",
    "                file.write(conversation)\n",
    "                \n",
    "            # Verify the HTML file was created and has valid content\n",
    "            if os.path.exists(file_path + \".html\") and os.path.getsize(file_path + \".html\") > 30:  # Threshold for meaningful content\n",
    "                os.remove(file_path + \".md\")  # Delete the .md file\n",
    "                extension = \".html\"\n",
    "                \n",
    "            else:\n",
    "            # keep the markdown file if the HTML file is empty or has insufficient content\n",
    "                extension = \".md\"\n",
    "                raise ValueError(\"HTML file is empty or has insufficient content.\")\n",
    "              \n",
    "                \n",
    "                  \n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "        \n",
    "        display(Markdown(f\"### __The conversation has been saved as {name}.{extension}__\"))    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot = Chatbot(\n",
    "    model_name=\"gpt-4o\",\n",
    "    system_role_content=\"\"\"You are a tech expert. \"\"\",\n",
    "    max_inputs=50,\n",
    "    tone=\"CREATIVE\",\n",
    ")\n",
    "\n",
    "chatbot.chat()       "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
